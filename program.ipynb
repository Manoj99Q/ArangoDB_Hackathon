{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for debugger to attach...\n"
     ]
    }
   ],
   "source": [
    "# Enable remote debugging\n",
    "import debugpy\n",
    "import os\n",
    "\n",
    "# Only enable debugging if not already enabled\n",
    "if not debugpy.is_client_connected():\n",
    "    debugpy.listen((\"localhost\", 5678))\n",
    "    print(\"Waiting for debugger to attach...\")\n",
    "    debugpy.wait_for_client()\n",
    "    print(\"Debugger attached!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:33:26 -0600] [INFO]: NetworkX-cuGraph is unavailable: No module named 'nx_cugraph'.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import nx_arangodb as nxadb\n",
    "\n",
    "from arango import ArangoClient\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import re\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.graphs import ArangoGraph\n",
    "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from graph_utils import create_d3_visualization\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from agent_utils import GraphAgent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access variables\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "arango_host = os.getenv('ARANGO_HOST')\n",
    "arango_user = os.getenv('ARANGO_USER')\n",
    "arango_password = os.getenv('ARANGO_PASSWORD')\n",
    "arango_db = os.getenv('ARANGO_DB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '195136', 'name': '_analyzers', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '195138', 'name': '_queues', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '195137', 'name': '_aqlfunctions', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '211044', 'name': 'Users', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '195139', 'name': '_jobs', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '211045', 'name': 'Games', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '195141', 'name': '_appbundles', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '195135', 'name': '_graphs', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '195140', 'name': '_apps', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '211046', 'name': 'plays', 'system': False, 'type': 'edge', 'status': 'loaded'}, {'id': '195142', 'name': '_frontend', 'system': True, 'type': 'document', 'status': 'loaded'}]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the client for ArangoDB.\n",
    "client = ArangoClient(hosts=arango_host)\n",
    "db = client.db(arango_db, username=arango_user, password=arango_password)\n",
    "print(db.collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:33:35 -0600] [INFO]: Graph 'SteamGraph' exists.\n",
      "[20:33:35 -0600] [INFO]: Default node type set to 'Games'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph named 'SteamGraph' with 14950 nodes and 70477 edges\n"
     ]
    }
   ],
   "source": [
    "\n",
    "G_adb = nxadb.Graph(name=\"SteamGraph\", db=db)\n",
    "\n",
    "print(G_adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_key': 'SteamGraph', '_id': '_graphs/SteamGraph', '_rev': '_jQXYaFm---', 'edgeDefinitions': [{'collection': 'plays', 'from': ['Users'], 'to': ['Games']}], 'orphanCollections': [], 'networkx': {'name': 'SteamGraph'}}\n"
     ]
    }
   ],
   "source": [
    "graph_def = db.collection(\"_graphs\").get(\"SteamGraph\")\n",
    "print(graph_def)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users/164473026 Users/164473026\n",
      "Users/70703031 Users/70703031\n",
      "Users/121808566 Users/121808566\n",
      "Games/14533_commandos_beyond_the_call_of_duty Games/14533_commandos_beyond_the_call_of_duty\n",
      "Games/12314_onimusha_3_demon_siege Games/12314_onimusha_3_demon_siege\n",
      "Users/173606939 Users/173606939\n",
      "Users/303846149 Users/303846149\n",
      "Games/13027_insaniquarium_deluxe Games/13027_insaniquarium_deluxe\n",
      "Users/211315837 Users/211315837\n",
      "Users/29962674 Users/29962674\n"
     ]
    }
   ],
   "source": [
    "for node, data in list(G_adb.nodes(data=True))[:10]:\n",
    "    print(node, data.get(\"_id\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph named 'SteamGraph' with 14950 nodes and 70477 edges\n"
     ]
    }
   ],
   "source": [
    "print(G_adb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AQL Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections:\n",
      "_analyzers\n",
      "_queues\n",
      "_aqlfunctions\n",
      "Users\n",
      "_jobs\n",
      "Games\n",
      "_appbundles\n",
      "_graphs\n",
      "_apps\n",
      "plays\n",
      "_frontend\n",
      "\n",
      "Graph collections:\n",
      "[{'edge_collection': 'plays', 'from_vertex_collections': ['Users'], 'to_vertex_collections': ['Games']}]\n"
     ]
    }
   ],
   "source": [
    "# First, let's check what collections exist\n",
    "print(\"Available collections:\")\n",
    "for collection in db.collections():\n",
    "    print(collection['name'])\n",
    "\n",
    "# Get the graph to see its collections\n",
    "graph = db.graph('SteamGraph')\n",
    "print(\"\\nGraph collections:\")\n",
    "print(graph.edge_definitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Users Nodes:\n",
      "{'_key': '152639272', '_id': 'Users/152639272', '_rev': '_jPaYbqe--F', 'type': 'Users', 'steamid': 152639272}\n",
      "{'_key': '284999400', '_id': 'Users/284999400', '_rev': '_jPaYbkm--N', 'type': 'Users', 'steamid': 284999400}\n",
      "{'_key': '22470137', '_id': 'Users/22470137', '_rev': '_jPaYbqO--c', 'type': 'Users', 'steamid': 22470137}\n",
      "----------\n",
      "Sample Plays Edges:\n",
      "{'_key': '67965', '_id': 'plays/67965', '_from': 'Users/287500646', '_to': 'Games/11849_napoleon_total_war', '_rev': '_jPaYizm--b', 'weight': 0.7}\n",
      "{'_key': '28635', '_id': 'plays/28635', '_from': 'Users/99083518', '_to': 'Games/11364_dragon_age_origins_ultimate_edition', '_rev': '_jPaYgq---H', 'weight': 32}\n",
      "{'_key': '5886', '_id': 'plays/5886', '_from': 'Users/193494703', '_to': 'Games/11371_dota_2', '_rev': '_jPaYfU---M', 'weight': 13.4}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Query 3 random nodes from the Users collection.\n",
    "# -----------------------------------------------------------\n",
    "result_cursor = G_adb.query(\"\"\"\n",
    "    FOR node IN Users\n",
    "        SORT RAND()\n",
    "        LIMIT 3\n",
    "        RETURN node\n",
    "\"\"\")\n",
    "print(\"Sample Users Nodes:\")\n",
    "for node in result_cursor:\n",
    "    print(node)\n",
    "print('-'*10)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Query 3 random edges from the plays edge collection.\n",
    "# -----------------------------------------------------------\n",
    "result_cursor = G_adb.query(\"\"\"\n",
    "    FOR edge IN plays\n",
    "        SORT RAND()\n",
    "        LIMIT 3\n",
    "        RETURN edge\n",
    "\"\"\")\n",
    "print(\"Sample Plays Edges:\")\n",
    "for edge in result_cursor:\n",
    "    print(edge)\n",
    "print('-'*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arango_graph = ArangoGraph(db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = GraphAgent(arango_graph, G_adb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface(agent):\n",
    "    def display_response(input_text):\n",
    "        result = agent.query_graph(input_text)  # Assuming this is your existing processing function\n",
    "        return (\n",
    "            gr.HTML(value=result[\"html_code\"]),\n",
    "            result[\"reply\"]\n",
    "        )\n",
    "    \n",
    "    with gr.Blocks() as interface:\n",
    "        gr.Markdown(\"# Interactive Chat Interface\")\n",
    "        \n",
    "        input_text = gr.Textbox(\n",
    "            label=\"Your Input\",\n",
    "            placeholder=\"Type your message here...\",\n",
    "            lines=2\n",
    "        )\n",
    "        \n",
    "        with gr.Row():\n",
    "            submit_btn = gr.Button(\"Submit\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            html_output = gr.HTML(label=\"Visualization\")\n",
    "            text_output = gr.Textbox(label=\"Response\", lines=3)\n",
    "            \n",
    "        submit_btn.click(\n",
    "            fn=display_response,\n",
    "            inputs=[input_text],\n",
    "            outputs=[html_output, text_output]\n",
    "        )\n",
    "    \n",
    "    return interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [],\n",
      "  'iframe_html': '',\n",
      "  'messages': [ HumanMessage(content='Total number of games in the graph', additional_kwargs={}, response_metadata={}, id='1eea3179-e899-4d1e-9213-f10dc70f1ea0')],\n",
      "  'user_query': 'Total number of games in the graph',\n",
      "  'vis_messages': []}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH Games\n",
      "RETURN LENGTH(FOR game IN Games RETURN game)\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[3600]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "print AQL tool result\n",
      "{'query': 'RETURN LENGTH(FOR game IN Games RETURN game)', 'result': 'The total number of games in the database is 3,600.', 'aql_query': '\\nWITH Games\\nRETURN LENGTH(FOR game IN Games RETURN game)\\n', 'aql_result': [3600]}\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [ { 'aql_result': [3600],\n",
      "              'description': 'The total number of games in the database is '\n",
      "                             '3,600.'}],\n",
      "  'iframe_html': '',\n",
      "  'messages': [ HumanMessage(content='Total number of games in the graph', additional_kwargs={}, response_metadata={}, id='1eea3179-e899-4d1e-9213-f10dc70f1ea0'),\n",
      "                AIMessage(content=\"To find the total number of games in the graph, we need to query the 'Games' collection in the 'SteamGraph'. Here's the plan:\\n\\n1. Use the `AQL_QueryWrapper` tool to execute an AQL query that counts the number of documents in the 'Games' collection.\\n\\nLet's proceed with this plan.\", additional_kwargs={'tool_calls': [{'id': 'call_UXOKuCr96QrPKwGWNQcSJsoQ', 'function': {'arguments': '{\"query\":\"RETURN LENGTH(FOR game IN Games RETURN game)\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 736, 'total_tokens': 830, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-15f28014-34c7-4a3b-91e7-b74ce91a34d6-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'RETURN LENGTH(FOR game IN Games RETURN game)'}, 'id': 'call_UXOKuCr96QrPKwGWNQcSJsoQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 736, 'output_tokens': 94, 'total_tokens': 830, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The total number of games in the database is 3,600.', name='AQL_QueryWrapper', id='9c3ec8ec-2ea7-4ec3-a4a2-80140504f67b', tool_call_id='call_UXOKuCr96QrPKwGWNQcSJsoQ')],\n",
      "  'user_query': 'Total number of games in the graph',\n",
      "  'vis_messages': []}\n",
      "Visualizer State:\n",
      "{ 'data': [ { 'aql_result': [3600],\n",
      "              'description': 'The total number of games in the database is '\n",
      "                             '3,600.'}],\n",
      "  'iframe_html': '',\n",
      "  'messages': [ HumanMessage(content='Total number of games in the graph', additional_kwargs={}, response_metadata={}, id='1eea3179-e899-4d1e-9213-f10dc70f1ea0'),\n",
      "                AIMessage(content=\"To find the total number of games in the graph, we need to query the 'Games' collection in the 'SteamGraph'. Here's the plan:\\n\\n1. Use the `AQL_QueryWrapper` tool to execute an AQL query that counts the number of documents in the 'Games' collection.\\n\\nLet's proceed with this plan.\", additional_kwargs={'tool_calls': [{'id': 'call_UXOKuCr96QrPKwGWNQcSJsoQ', 'function': {'arguments': '{\"query\":\"RETURN LENGTH(FOR game IN Games RETURN game)\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 736, 'total_tokens': 830, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-15f28014-34c7-4a3b-91e7-b74ce91a34d6-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'RETURN LENGTH(FOR game IN Games RETURN game)'}, 'id': 'call_UXOKuCr96QrPKwGWNQcSJsoQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 736, 'output_tokens': 94, 'total_tokens': 830, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The total number of games in the database is 3,600.', name='AQL_QueryWrapper', id='9c3ec8ec-2ea7-4ec3-a4a2-80140504f67b', tool_call_id='call_UXOKuCr96QrPKwGWNQcSJsoQ'),\n",
      "                AIMessage(content='The total number of games in the graph is 3,600.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 855, 'total_tokens': 871, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-50279933-5ee3-4d7c-a220-f6b6054ef98a-0', usage_metadata={'input_tokens': 855, 'output_tokens': 16, 'total_tokens': 871, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
      "  'user_query': 'Total number of games in the graph',\n",
      "  'vis_messages': []}\n",
      "Going to Vis Tools after Visualizaer\n",
      "Visualizer State:\n",
      "{ 'data': [ { 'aql_result': [3600],\n",
      "              'description': 'The total number of games in the database is '\n",
      "                             '3,600.'}],\n",
      "  'iframe_html': '',\n",
      "  'messages': [ HumanMessage(content='Total number of games in the graph', additional_kwargs={}, response_metadata={}, id='1eea3179-e899-4d1e-9213-f10dc70f1ea0'),\n",
      "                AIMessage(content=\"To find the total number of games in the graph, we need to query the 'Games' collection in the 'SteamGraph'. Here's the plan:\\n\\n1. Use the `AQL_QueryWrapper` tool to execute an AQL query that counts the number of documents in the 'Games' collection.\\n\\nLet's proceed with this plan.\", additional_kwargs={'tool_calls': [{'id': 'call_UXOKuCr96QrPKwGWNQcSJsoQ', 'function': {'arguments': '{\"query\":\"RETURN LENGTH(FOR game IN Games RETURN game)\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 736, 'total_tokens': 830, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-15f28014-34c7-4a3b-91e7-b74ce91a34d6-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'RETURN LENGTH(FOR game IN Games RETURN game)'}, 'id': 'call_UXOKuCr96QrPKwGWNQcSJsoQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 736, 'output_tokens': 94, 'total_tokens': 830, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The total number of games in the database is 3,600.', name='AQL_QueryWrapper', id='9c3ec8ec-2ea7-4ec3-a4a2-80140504f67b', tool_call_id='call_UXOKuCr96QrPKwGWNQcSJsoQ'),\n",
      "                AIMessage(content='The total number of games in the graph is 3,600.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 855, 'total_tokens': 871, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-50279933-5ee3-4d7c-a220-f6b6054ef98a-0', usage_metadata={'input_tokens': 855, 'output_tokens': 16, 'total_tokens': 871, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
      "  'user_query': 'Total number of games in the graph',\n",
      "  'vis_messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mfQV3Ec5MOzIwJiufyIPZjmK', 'function': {'arguments': '{\"query\":\"Visualize the total number of games, which is 3,600, as a single bar in a bar chart.\"}', 'name': 'graph_vis_Wrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 102, 'total_tokens': 142, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e12fbcd8-d2ad-448d-8632-3590196dd046-0', tool_calls=[{'name': 'graph_vis_Wrapper', 'args': {'query': 'Visualize the total number of games, which is 3,600, as a single bar in a bar chart.'}, 'id': 'call_mfQV3Ec5MOzIwJiufyIPZjmK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 102, 'output_tokens': 40, 'total_tokens': 142, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/gradio/blocks.py\", line 2098, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/gradio/blocks.py\", line 1645, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/gradio/utils.py\", line 883, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_205717/1825052705.py\", line 3, in display_response\n",
      "    result = agent.query_graph(input_text)  # Assuming this is your existing processing function\n",
      "  File \"/mnt/mydisk/Projects/ArangoGraphRag/agent_utils.py\", line 510, in query_graph\n",
      "    final_state = self.agent.invoke(initial_state)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/pregel/__init__.py\", line 2069, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/pregel/__init__.py\", line 1724, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/utils/runnable.py\", line 506, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/utils/runnable.py\", line 270, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "  File \"/mnt/mydisk/Projects/ArangoGraphRag/agent_utils.py\", line 352, in Visualizer\n",
      "    new_ai_message = chain.invoke(state)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5360, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 284, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 860, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 690, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 925, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 792, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 879, in create\n",
      "    return self._post(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "  File \"/home/manoj99/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_mfQV3Ec5MOzIwJiufyIPZjmK\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "interface = create_gradio_interface(agent)\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [],\n",
      "  'iframe_html': '',\n",
      "  'messages': [ HumanMessage(content='Total number of games in the graph', additional_kwargs={}, response_metadata={}, id='c89834f0-4e1b-4afc-b973-d2750a7efa30')],\n",
      "  'user_query': 'Total number of games in the graph',\n",
      "  'vis_messages': []}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH Games\n",
      "FOR game IN Games\n",
      "COLLECT WITH COUNT INTO length\n",
      "RETURN length\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[3600]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "print AQL tool result\n",
      "{'query': 'FOR game IN Games COLLECT WITH COUNT INTO length RETURN length', 'result': 'The total number of games in the database is 3,600.', 'aql_query': '\\nWITH Games\\nFOR game IN Games\\nCOLLECT WITH COUNT INTO length\\nRETURN length\\n', 'aql_result': [3600]}\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [ { 'aql_result': [3600],\n",
      "              'description': 'The total number of games in the database is '\n",
      "                             '3,600.'}],\n",
      "  'iframe_html': '',\n",
      "  'messages': [ HumanMessage(content='Total number of games in the graph', additional_kwargs={}, response_metadata={}, id='c89834f0-4e1b-4afc-b973-d2750a7efa30'),\n",
      "                AIMessage(content=\"To find the total number of games in the graph, we need to query the `Games` collection in the `SteamGraph`. Here's the plan:\\n\\n1. Use the `AQL_QueryWrapper` tool to execute an AQL query that counts the total number of documents in the `Games` collection.\\n\\nLet's proceed with this plan.\", additional_kwargs={'tool_calls': [{'id': 'call_SVXjKTZEP4XNEOX1sdjmXGqh', 'function': {'arguments': '{\"query\":\"FOR game IN Games COLLECT WITH COUNT INTO length RETURN length\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 736, 'total_tokens': 833, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f44cfcf8-4cf5-4465-8bfc-5b27c476751a-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'FOR game IN Games COLLECT WITH COUNT INTO length RETURN length'}, 'id': 'call_SVXjKTZEP4XNEOX1sdjmXGqh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 736, 'output_tokens': 97, 'total_tokens': 833, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The total number of games in the database is 3,600.', name='AQL_QueryWrapper', id='dff8bac5-cfae-4841-a6c9-f0eac7c1e726', tool_call_id='call_SVXjKTZEP4XNEOX1sdjmXGqh')],\n",
      "  'user_query': 'Total number of games in the graph',\n",
      "  'vis_messages': []}\n",
      "Visualizer State:\n",
      "{ 'data': [ { 'aql_result': [3600],\n",
      "              'description': 'The total number of games in the database is '\n",
      "                             '3,600.'}],\n",
      "  'iframe_html': '',\n",
      "  'messages': [ HumanMessage(content='Total number of games in the graph', additional_kwargs={}, response_metadata={}, id='c89834f0-4e1b-4afc-b973-d2750a7efa30'),\n",
      "                AIMessage(content=\"To find the total number of games in the graph, we need to query the `Games` collection in the `SteamGraph`. Here's the plan:\\n\\n1. Use the `AQL_QueryWrapper` tool to execute an AQL query that counts the total number of documents in the `Games` collection.\\n\\nLet's proceed with this plan.\", additional_kwargs={'tool_calls': [{'id': 'call_SVXjKTZEP4XNEOX1sdjmXGqh', 'function': {'arguments': '{\"query\":\"FOR game IN Games COLLECT WITH COUNT INTO length RETURN length\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 736, 'total_tokens': 833, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f44cfcf8-4cf5-4465-8bfc-5b27c476751a-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'FOR game IN Games COLLECT WITH COUNT INTO length RETURN length'}, 'id': 'call_SVXjKTZEP4XNEOX1sdjmXGqh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 736, 'output_tokens': 97, 'total_tokens': 833, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The total number of games in the database is 3,600.', name='AQL_QueryWrapper', id='dff8bac5-cfae-4841-a6c9-f0eac7c1e726', tool_call_id='call_SVXjKTZEP4XNEOX1sdjmXGqh'),\n",
      "                AIMessage(content='The total number of games in the graph is 3,600.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 858, 'total_tokens': 874, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-0636f4fb-707e-4642-bd36-8e1c1fc80360-0', usage_metadata={'input_tokens': 858, 'output_tokens': 16, 'total_tokens': 874, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
      "  'user_query': 'Total number of games in the graph',\n",
      "  'vis_messages': []}\n",
      "Visualizer State:\n",
      "{ 'data': [ { 'aql_result': [3600],\n",
      "              'description': 'The total number of games in the database is '\n",
      "                             '3,600.'}],\n",
      "  'iframe_html': '',\n",
      "  'messages': [ HumanMessage(content='Total number of games in the graph', additional_kwargs={}, response_metadata={}, id='c89834f0-4e1b-4afc-b973-d2750a7efa30'),\n",
      "                AIMessage(content=\"To find the total number of games in the graph, we need to query the `Games` collection in the `SteamGraph`. Here's the plan:\\n\\n1. Use the `AQL_QueryWrapper` tool to execute an AQL query that counts the total number of documents in the `Games` collection.\\n\\nLet's proceed with this plan.\", additional_kwargs={'tool_calls': [{'id': 'call_SVXjKTZEP4XNEOX1sdjmXGqh', 'function': {'arguments': '{\"query\":\"FOR game IN Games COLLECT WITH COUNT INTO length RETURN length\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 736, 'total_tokens': 833, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f44cfcf8-4cf5-4465-8bfc-5b27c476751a-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'FOR game IN Games COLLECT WITH COUNT INTO length RETURN length'}, 'id': 'call_SVXjKTZEP4XNEOX1sdjmXGqh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 736, 'output_tokens': 97, 'total_tokens': 833, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The total number of games in the database is 3,600.', name='AQL_QueryWrapper', id='dff8bac5-cfae-4841-a6c9-f0eac7c1e726', tool_call_id='call_SVXjKTZEP4XNEOX1sdjmXGqh'),\n",
      "                AIMessage(content='The total number of games in the graph is 3,600.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 858, 'total_tokens': 874, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-0636f4fb-707e-4642-bd36-8e1c1fc80360-0', usage_metadata={'input_tokens': 858, 'output_tokens': 16, 'total_tokens': 874, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
      "  'user_query': 'Total number of games in the graph',\n",
      "  'vis_messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fOkCJBSahGTcMy4sZR9Tl6qK', 'function': {'arguments': '{\"query\":\"Visualize the total number of games, which is 3,600, as a single bar in a bar chart labeled \\'Total Games\\'.\"}', 'name': 'graph_vis_Wrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 102, 'total_tokens': 147, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-56698e6c-7998-4e64-92c2-2bcbd0247ab1-0', tool_calls=[{'name': 'graph_vis_Wrapper', 'args': {'query': \"Visualize the total number of games, which is 3,600, as a single bar in a bar chart labeled 'Total Games'.\"}, 'id': 'call_fOkCJBSahGTcMy4sZR9Tl6qK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 102, 'output_tokens': 45, 'total_tokens': 147, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_fOkCJBSahGTcMy4sZR9Tl6qK\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTotal number of games in the graph\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/mydisk/Projects/ArangoGraphRag/agent_utils.py:499\u001b[0m, in \u001b[0;36mGraphAgent.query_graph\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    490\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39mquery)],\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvis_messages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miframe_html\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Initialize empty iframe\u001b[39;00m\n\u001b[1;32m    496\u001b[0m }\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# Use invoke() instead of stream() to get final state directly\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m final_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Answer:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    502\u001b[0m pprint(final_state, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2069\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2068\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2069\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2070\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2071\u001b[0m     config,\n\u001b[1;32m   2072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2073\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2074\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2075\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2076\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2077\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2078\u001b[0m ):\n\u001b[1;32m   2079\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2080\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1729\u001b[0m         ):\n\u001b[1;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/utils/runnable.py:506\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    503\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    504\u001b[0m )\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langgraph/utils/runnable.py:270\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 270\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/mnt/mydisk/Projects/ArangoGraphRag/agent_utils.py:341\u001b[0m, in \u001b[0;36mGraphAgent.Visualizer\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    334\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[1;32m    335\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a visualization expert. Create visual representations of the data.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    336\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualize for: \u001b[39m\u001b[38;5;132;01m{user_query}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData: \u001b[39m\u001b[38;5;132;01m{data}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    337\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplaceholder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{vis_messages}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    338\u001b[0m ])\n\u001b[1;32m    340\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind_tools(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisualization_tools)\n\u001b[0;32m--> 341\u001b[0m new_ai_message \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvis_messages\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvis_messages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [new_ai_message]\n\u001b[1;32m    345\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/runnables/base.py:5360\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5355\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5356\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5357\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5358\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5359\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5361\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:792\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 792\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:879\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    877\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    878\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Arrongo/lib/python3.10/site-packages/openai/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1070\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1074\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1080\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_fOkCJBSahGTcMy4sZR9Tl6qK\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}"
     ]
    }
   ],
   "source": [
    "response = agent.query_graph(\"Total number of games in the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [],\n",
      "  'messages': [ HumanMessage(content='Users who have played the most influential game', additional_kwargs={}, response_metadata={}, id='76b887bb-0451-4af5-b2a3-c0a4803e6726')],\n",
      "  'user_query': 'Users who have played the most influential game'}\n",
      "Netwrokx Query received:\n",
      "Calculate degree centrality for Games and find the game with the highest centrality.\n",
      "----------\n",
      "1) Generating NetworkX code\n",
      "----------\n",
      "import networkx as nx\n",
      "\n",
      "# Assuming G_adb is already defined and is a NetworkX graph object\n",
      "\n",
      "# Calculate degree centrality for Games\n",
      "# Degree centrality for a node v is the fraction of nodes it is connected to.\n",
      "# Since we are interested in Games, we need to filter nodes of type 'Games'\n",
      "\n",
      "# Extract all game nodes\n",
      "game_nodes = [n for n, attr in G_adb.nodes(data=True) if attr.get('type') == 'Games']\n",
      "\n",
      "# Calculate degree centrality for all nodes\n",
      "degree_centrality = nx.degree_centrality(G_adb)\n",
      "\n",
      "# Filter degree centrality to only include game nodes\n",
      "game_degree_centrality = {node: degree_centrality[node] for node in game_nodes}\n",
      "\n",
      "# Find the game with the highest centrality\n",
      "max_centrality_game = max(game_degree_centrality, key=game_degree_centrality.get)\n",
      "\n",
      "# Retrieve the node object with all properties\n",
      "FINAL_RESULT = G_adb.nodes[max_centrality_game]\n",
      "----------\n",
      "\n",
      "2) Executing NetworkX code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:56:09 -0600] [INFO]: Graph 'SteamGraph' load took 2.3767833709716797s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXEC ERROR: name 'degree_centrality' is not defined\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [],\n",
      "  'messages': [ HumanMessage(content='Users who have played the most influential game', additional_kwargs={}, response_metadata={}, id='76b887bb-0451-4af5-b2a3-c0a4803e6726'),\n",
      "                AIMessage(content='To determine the users who have played the most influential game, we need to follow these steps:\\n\\n1. **Identify the Most Influential Game**: We need to determine which game is the most influential. This could be interpreted as the game with the highest number of players or the game with the highest total playtime. We will use the `NX_QueryWrapper` to analyze the graph and find the game with the highest centrality or degree.\\n\\n2. **Find Users Who Played This Game**: Once we have identified the most influential game, we will query the graph to find all users who have played this game using the `AQL_QueryWrapper`.\\n\\nLet\\'s execute these steps. \\n\\n### Step 1: Identify the Most Influential Game\\nWe will use the `NX_QueryWrapper` to find the game with the highest degree centrality, which indicates the game with the most connections (players).\\n\\n```json\\n{\\n  \"query\": \"Calculate degree centrality for Games and find the game with the highest centrality.\"\\n}\\n```', additional_kwargs={'tool_calls': [{'id': 'call_23mckoa7YgL8koWXOwlV0gBe', 'function': {'arguments': '{\"query\":\"Calculate degree centrality for Games and find the game with the highest centrality.\"}', 'name': 'NX_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 738, 'total_tokens': 979, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3a180243-c05e-4e76-979e-0c3f6ad675a2-0', tool_calls=[{'name': 'NX_QueryWrapper', 'args': {'query': 'Calculate degree centrality for Games and find the game with the highest centrality.'}, 'id': 'call_23mckoa7YgL8koWXOwlV0gBe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 738, 'output_tokens': 241, 'total_tokens': 979, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content=\"EXEC ERROR: name 'degree_centrality' is not defined\", name='NX_QueryWrapper', id='0f813adc-208c-49c8-a5ff-a77508398bb8', tool_call_id='call_23mckoa7YgL8koWXOwlV0gBe')],\n",
      "  'user_query': 'Users who have played the most influential game'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH Games, plays\n",
      "FOR game IN Games \n",
      "  LET playerCount = (\n",
      "    FOR play IN plays \n",
      "    FILTER play._to == game._id \n",
      "    COLLECT WITH COUNT INTO length \n",
      "    RETURN length\n",
      "  )[0] \n",
      "  SORT playerCount DESC \n",
      "  LIMIT 1 \n",
      "  RETURN {game: game.GameName, playerCount: playerCount}\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[{'game': 'Dota 2', 'playerCount': 4841}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "print AQL tool result\n",
      "{'query': 'FOR game IN Games LET playerCount = (FOR play IN plays FILTER play._to == game._id COLLECT WITH COUNT INTO length RETURN length)[0] SORT playerCount DESC LIMIT 1 RETURN {game: game.GameName, playerCount: playerCount}', 'result': 'The game with the highest number of players is \"Dota 2,\" with a total of 4,841 players.', 'aql_query': '\\nWITH Games, plays\\nFOR game IN Games \\n  LET playerCount = (\\n    FOR play IN plays \\n    FILTER play._to == game._id \\n    COLLECT WITH COUNT INTO length \\n    RETURN length\\n  )[0] \\n  SORT playerCount DESC \\n  LIMIT 1 \\n  RETURN {game: game.GameName, playerCount: playerCount}\\n', 'aql_result': [{'game': 'Dota 2', 'playerCount': 4841}]}\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [ { 'aql_result': [{'game': 'Dota 2', 'playerCount': 4841}],\n",
      "              'description': 'The game with the highest number of players is '\n",
      "                             '\"Dota 2,\" with a total of 4,841 players.'}],\n",
      "  'messages': [ HumanMessage(content='Users who have played the most influential game', additional_kwargs={}, response_metadata={}, id='76b887bb-0451-4af5-b2a3-c0a4803e6726'),\n",
      "                AIMessage(content='To determine the users who have played the most influential game, we need to follow these steps:\\n\\n1. **Identify the Most Influential Game**: We need to determine which game is the most influential. This could be interpreted as the game with the highest number of players or the game with the highest total playtime. We will use the `NX_QueryWrapper` to analyze the graph and find the game with the highest centrality or degree.\\n\\n2. **Find Users Who Played This Game**: Once we have identified the most influential game, we will query the graph to find all users who have played this game using the `AQL_QueryWrapper`.\\n\\nLet\\'s execute these steps. \\n\\n### Step 1: Identify the Most Influential Game\\nWe will use the `NX_QueryWrapper` to find the game with the highest degree centrality, which indicates the game with the most connections (players).\\n\\n```json\\n{\\n  \"query\": \"Calculate degree centrality for Games and find the game with the highest centrality.\"\\n}\\n```', additional_kwargs={'tool_calls': [{'id': 'call_23mckoa7YgL8koWXOwlV0gBe', 'function': {'arguments': '{\"query\":\"Calculate degree centrality for Games and find the game with the highest centrality.\"}', 'name': 'NX_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 738, 'total_tokens': 979, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3a180243-c05e-4e76-979e-0c3f6ad675a2-0', tool_calls=[{'name': 'NX_QueryWrapper', 'args': {'query': 'Calculate degree centrality for Games and find the game with the highest centrality.'}, 'id': 'call_23mckoa7YgL8koWXOwlV0gBe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 738, 'output_tokens': 241, 'total_tokens': 979, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content=\"EXEC ERROR: name 'degree_centrality' is not defined\", name='NX_QueryWrapper', id='0f813adc-208c-49c8-a5ff-a77508398bb8', tool_call_id='call_23mckoa7YgL8koWXOwlV0gBe'),\n",
      "                AIMessage(content='It seems there was an error with the query execution. Let\\'s try a different approach to identify the most influential game by finding the game with the highest number of players using the `AQL_QueryWrapper`.\\n\\n### Step 1 (Alternative): Identify the Most Influential Game\\nWe will use an AQL query to find the game with the highest number of players.\\n\\n```json\\n{\\n  \"query\": \"FOR game IN Games LET playerCount = (FOR play IN plays FILTER play._to == game._id COLLECT WITH COUNT INTO length RETURN length)[0] SORT playerCount DESC LIMIT 1 RETURN {game: game.GameName, playerCount: playerCount}\"\\n}\\n```', additional_kwargs={'tool_calls': [{'id': 'call_qJeU4WpqrGOgoupJexZnFUNI', 'function': {'arguments': '{\"query\":\"FOR game IN Games LET playerCount = (FOR play IN plays FILTER play._to == game._id COLLECT WITH COUNT INTO length RETURN length)[0] SORT playerCount DESC LIMIT 1 RETURN {game: game.GameName, playerCount: playerCount}\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 1002, 'total_tokens': 1209, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-189b5207-550c-4491-9a87-867e8cf69a0d-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'FOR game IN Games LET playerCount = (FOR play IN plays FILTER play._to == game._id COLLECT WITH COUNT INTO length RETURN length)[0] SORT playerCount DESC LIMIT 1 RETURN {game: game.GameName, playerCount: playerCount}'}, 'id': 'call_qJeU4WpqrGOgoupJexZnFUNI', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1002, 'output_tokens': 207, 'total_tokens': 1209, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The game with the highest number of players is \"Dota 2,\" with a total of 4,841 players.', name='AQL_QueryWrapper', id='21cc6bb6-77d5-4768-9ab0-146cd2afdd95', tool_call_id='call_qJeU4WpqrGOgoupJexZnFUNI')],\n",
      "  'user_query': 'Users who have played the most influential game'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH plays, Users\n",
      "FOR play IN plays\n",
      "  FILTER play._to == 'Games/dota_2'\n",
      "  FOR user IN Users\n",
      "    FILTER user._id == play._from\n",
      "    RETURN user.steamid\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "print AQL tool result\n",
      "{'query': \"FOR play IN plays FILTER play._to == 'Games/dota_2' FOR user IN Users FILTER user._id == play._from RETURN user.steamid\", 'result': 'Summary:\\n\\nThere are no users in the database who have played the game \"Dota 2.\"', 'aql_query': \"\\nWITH plays, Users\\nFOR play IN plays\\n  FILTER play._to == 'Games/dota_2'\\n  FOR user IN Users\\n    FILTER user._id == play._from\\n    RETURN user.steamid\\n\", 'aql_result': []}\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [ { 'aql_result': [{'game': 'Dota 2', 'playerCount': 4841}],\n",
      "              'description': 'The game with the highest number of players is '\n",
      "                             '\"Dota 2,\" with a total of 4,841 players.'},\n",
      "            { 'aql_result': [],\n",
      "              'description': 'Summary:\\n'\n",
      "                             '\\n'\n",
      "                             'There are no users in the database who have '\n",
      "                             'played the game \"Dota 2.\"'}],\n",
      "  'messages': [ HumanMessage(content='Users who have played the most influential game', additional_kwargs={}, response_metadata={}, id='76b887bb-0451-4af5-b2a3-c0a4803e6726'),\n",
      "                AIMessage(content='To determine the users who have played the most influential game, we need to follow these steps:\\n\\n1. **Identify the Most Influential Game**: We need to determine which game is the most influential. This could be interpreted as the game with the highest number of players or the game with the highest total playtime. We will use the `NX_QueryWrapper` to analyze the graph and find the game with the highest centrality or degree.\\n\\n2. **Find Users Who Played This Game**: Once we have identified the most influential game, we will query the graph to find all users who have played this game using the `AQL_QueryWrapper`.\\n\\nLet\\'s execute these steps. \\n\\n### Step 1: Identify the Most Influential Game\\nWe will use the `NX_QueryWrapper` to find the game with the highest degree centrality, which indicates the game with the most connections (players).\\n\\n```json\\n{\\n  \"query\": \"Calculate degree centrality for Games and find the game with the highest centrality.\"\\n}\\n```', additional_kwargs={'tool_calls': [{'id': 'call_23mckoa7YgL8koWXOwlV0gBe', 'function': {'arguments': '{\"query\":\"Calculate degree centrality for Games and find the game with the highest centrality.\"}', 'name': 'NX_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 738, 'total_tokens': 979, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3a180243-c05e-4e76-979e-0c3f6ad675a2-0', tool_calls=[{'name': 'NX_QueryWrapper', 'args': {'query': 'Calculate degree centrality for Games and find the game with the highest centrality.'}, 'id': 'call_23mckoa7YgL8koWXOwlV0gBe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 738, 'output_tokens': 241, 'total_tokens': 979, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content=\"EXEC ERROR: name 'degree_centrality' is not defined\", name='NX_QueryWrapper', id='0f813adc-208c-49c8-a5ff-a77508398bb8', tool_call_id='call_23mckoa7YgL8koWXOwlV0gBe'),\n",
      "                AIMessage(content='It seems there was an error with the query execution. Let\\'s try a different approach to identify the most influential game by finding the game with the highest number of players using the `AQL_QueryWrapper`.\\n\\n### Step 1 (Alternative): Identify the Most Influential Game\\nWe will use an AQL query to find the game with the highest number of players.\\n\\n```json\\n{\\n  \"query\": \"FOR game IN Games LET playerCount = (FOR play IN plays FILTER play._to == game._id COLLECT WITH COUNT INTO length RETURN length)[0] SORT playerCount DESC LIMIT 1 RETURN {game: game.GameName, playerCount: playerCount}\"\\n}\\n```', additional_kwargs={'tool_calls': [{'id': 'call_qJeU4WpqrGOgoupJexZnFUNI', 'function': {'arguments': '{\"query\":\"FOR game IN Games LET playerCount = (FOR play IN plays FILTER play._to == game._id COLLECT WITH COUNT INTO length RETURN length)[0] SORT playerCount DESC LIMIT 1 RETURN {game: game.GameName, playerCount: playerCount}\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 1002, 'total_tokens': 1209, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-189b5207-550c-4491-9a87-867e8cf69a0d-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'FOR game IN Games LET playerCount = (FOR play IN plays FILTER play._to == game._id COLLECT WITH COUNT INTO length RETURN length)[0] SORT playerCount DESC LIMIT 1 RETURN {game: game.GameName, playerCount: playerCount}'}, 'id': 'call_qJeU4WpqrGOgoupJexZnFUNI', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1002, 'output_tokens': 207, 'total_tokens': 1209, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The game with the highest number of players is \"Dota 2,\" with a total of 4,841 players.', name='AQL_QueryWrapper', id='21cc6bb6-77d5-4768-9ab0-146cd2afdd95', tool_call_id='call_qJeU4WpqrGOgoupJexZnFUNI'),\n",
      "                AIMessage(content='The most influential game, based on the number of players, is \"Dota 2,\" with a total of 4,841 players.\\n\\n### Step 2: Find Users Who Played \"Dota 2\"\\nNow, we will find all users who have played \"Dota 2\" using the `AQL_QueryWrapper`.\\n\\n```json\\n{\\n  \"query\": \"FOR play IN plays FILTER play._to == \\'Games/dota_2\\' FOR user IN Users FILTER user._id == play._from RETURN user.steamid\"\\n}\\n```', additional_kwargs={'tool_calls': [{'id': 'call_aRFGLB6pV7ji0AFxA25LF3RR', 'function': {'arguments': '{\"query\":\"FOR play IN plays FILTER play._to == \\'Games/dota_2\\' FOR user IN Users FILTER user._id == play._from RETURN user.steamid\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 164, 'prompt_tokens': 1245, 'total_tokens': 1409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b92ac0fa-8840-4bc8-a3a1-0c84c6e86379-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': \"FOR play IN plays FILTER play._to == 'Games/dota_2' FOR user IN Users FILTER user._id == play._from RETURN user.steamid\"}, 'id': 'call_aRFGLB6pV7ji0AFxA25LF3RR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1245, 'output_tokens': 164, 'total_tokens': 1409, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='Summary:\\n\\nThere are no users in the database who have played the game \"Dota 2.\"', name='AQL_QueryWrapper', id='316030cf-c031-4feb-856f-a1246cbcdb7d', tool_call_id='call_aRFGLB6pV7ji0AFxA25LF3RR')],\n",
      "  'user_query': 'Users who have played the most influential game'}\n",
      "Final Answer:\n",
      "Visulaization Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Visulaization Done'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query_graph(\"Users who have played the most influential game\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [],\n",
      "  'messages': [ HumanMessage(content='Find 2nd and 4th Most influential game in the graph and its number of users who played both of them', additional_kwargs={}, response_metadata={}, id='800e2839-3631-462e-940b-74ec1e2c2b3c')],\n",
      "  'user_query': 'Find 2nd and 4th Most influential game in the graph and its '\n",
      "                'number of users who played both of them'}\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [],\n",
      "  'messages': [ HumanMessage(content='Find 2nd and 4th Most influential game in the graph and its number of users who played both of them', additional_kwargs={}, response_metadata={}, id='800e2839-3631-462e-940b-74ec1e2c2b3c'),\n",
      "                AIMessage(content=\"To address the query, we need to follow these steps:\\n\\n1. **Identify the Most Influential Games**: Use centrality measures to determine the influence of games in the graph. We will use NetworkX to calculate the centrality of each game and identify the 2nd and 4th most influential games.\\n\\n2. **Find Users Who Played Both Games**: Once we have identified the 2nd and 4th most influential games, we will query the graph to find users who have played both of these games.\\n\\nLet's execute this plan step-by-step.\\n\\n### Step 1: Identify the 2nd and 4th Most Influential Games\\n\\nWe will use NetworkX to calculate the centrality of each game and determine the 2nd and 4th most influential games.\", additional_kwargs={'tool_calls': [{'id': 'call_XetPBbkgE9BGUNh3fAdi8i9D', 'function': {'arguments': '{\"query\":\"Calculate the degree centrality for all games in the SteamGraph and return the 2nd and 4th most influential games based on their centrality scores.\"}', 'name': 'NX_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 211, 'prompt_tokens': 770, 'total_tokens': 981, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8d991e19-a7df-4f50-bf81-7c7d47d72922-0', tool_calls=[{'name': 'NX_QueryWrapper', 'args': {'query': 'Calculate the degree centrality for all games in the SteamGraph and return the 2nd and 4th most influential games based on their centrality scores.'}, 'id': 'call_XetPBbkgE9BGUNh3fAdi8i9D', 'type': 'tool_call'}], usage_metadata={'input_tokens': 770, 'output_tokens': 211, 'total_tokens': 981, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='null', name='NX_QueryWrapper', id='5d222471-7186-49c1-8bda-9b38acdf69cb', tool_call_id='call_XetPBbkgE9BGUNh3fAdi8i9D')],\n",
      "  'user_query': 'Find 2nd and 4th Most influential game in the graph and its '\n",
      "                'number of users who played both of them'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH Games, plays\n",
      "FOR game IN Games\n",
      "LET userCount = LENGTH(\n",
      "  FOR play IN plays\n",
      "  FILTER play._to == game._id\n",
      "  RETURN play\n",
      ")\n",
      "SORT userCount DESC\n",
      "LIMIT 4\n",
      "RETURN {game: game.GameName, userCount: userCount}\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[{'game': 'Dota 2', 'userCount': 4841}, {'game': 'Team Fortress 2', 'userCount': 2323}, {'game': 'Counter-Strike Global Offensive', 'userCount': 1377}, {'game': 'Unturned', 'userCount': 1069}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "print AQL tool result\n",
      "{'query': 'FOR game IN Games\\nLET userCount = LENGTH(\\n  FOR play IN plays\\n  FILTER play._to == game._id\\n  RETURN play\\n)\\nSORT userCount DESC\\nLIMIT 4\\nRETURN {game: game.GameName, userCount: userCount}', 'result': 'The query results indicate the four most popular games based on the number of users who have played them. The game \"Dota 2\" has the highest user count with 4,841 players. It is followed by \"Team Fortress 2\" with 2,323 players, \"Counter-Strike Global Offensive\" with 1,377 players, and \"Unturned\" with 1,069 players.', 'aql_query': '\\nWITH Games, plays\\nFOR game IN Games\\nLET userCount = LENGTH(\\n  FOR play IN plays\\n  FILTER play._to == game._id\\n  RETURN play\\n)\\nSORT userCount DESC\\nLIMIT 4\\nRETURN {game: game.GameName, userCount: userCount}\\n', 'aql_result': [{'game': 'Dota 2', 'userCount': 4841}, {'game': 'Team Fortress 2', 'userCount': 2323}, {'game': 'Counter-Strike Global Offensive', 'userCount': 1377}, {'game': 'Unturned', 'userCount': 1069}]}\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [ { 'aql_query': '\\n'\n",
      "                           'WITH Games, plays\\n'\n",
      "                           'FOR game IN Games\\n'\n",
      "                           'LET userCount = LENGTH(\\n'\n",
      "                           '  FOR play IN plays\\n'\n",
      "                           '  FILTER play._to == game._id\\n'\n",
      "                           '  RETURN play\\n'\n",
      "                           ')\\n'\n",
      "                           'SORT userCount DESC\\n'\n",
      "                           'LIMIT 4\\n'\n",
      "                           'RETURN {game: game.GameName, userCount: '\n",
      "                           'userCount}\\n',\n",
      "              'aql_result': [ {'game': 'Dota 2', 'userCount': 4841},\n",
      "                              {'game': 'Team Fortress 2', 'userCount': 2323},\n",
      "                              { 'game': 'Counter-Strike Global Offensive',\n",
      "                                'userCount': 1377},\n",
      "                              {'game': 'Unturned', 'userCount': 1069}],\n",
      "              'query': 'FOR game IN Games\\n'\n",
      "                       'LET userCount = LENGTH(\\n'\n",
      "                       '  FOR play IN plays\\n'\n",
      "                       '  FILTER play._to == game._id\\n'\n",
      "                       '  RETURN play\\n'\n",
      "                       ')\\n'\n",
      "                       'SORT userCount DESC\\n'\n",
      "                       'LIMIT 4\\n'\n",
      "                       'RETURN {game: game.GameName, userCount: userCount}',\n",
      "              'result': 'The query results indicate the four most popular '\n",
      "                        'games based on the number of users who have played '\n",
      "                        'them. The game \"Dota 2\" has the highest user count '\n",
      "                        'with 4,841 players. It is followed by \"Team Fortress '\n",
      "                        '2\" with 2,323 players, \"Counter-Strike Global '\n",
      "                        'Offensive\" with 1,377 players, and \"Unturned\" with '\n",
      "                        '1,069 players.'}],\n",
      "  'messages': [ HumanMessage(content='Find 2nd and 4th Most influential game in the graph and its number of users who played both of them', additional_kwargs={}, response_metadata={}, id='800e2839-3631-462e-940b-74ec1e2c2b3c'),\n",
      "                AIMessage(content=\"To address the query, we need to follow these steps:\\n\\n1. **Identify the Most Influential Games**: Use centrality measures to determine the influence of games in the graph. We will use NetworkX to calculate the centrality of each game and identify the 2nd and 4th most influential games.\\n\\n2. **Find Users Who Played Both Games**: Once we have identified the 2nd and 4th most influential games, we will query the graph to find users who have played both of these games.\\n\\nLet's execute this plan step-by-step.\\n\\n### Step 1: Identify the 2nd and 4th Most Influential Games\\n\\nWe will use NetworkX to calculate the centrality of each game and determine the 2nd and 4th most influential games.\", additional_kwargs={'tool_calls': [{'id': 'call_XetPBbkgE9BGUNh3fAdi8i9D', 'function': {'arguments': '{\"query\":\"Calculate the degree centrality for all games in the SteamGraph and return the 2nd and 4th most influential games based on their centrality scores.\"}', 'name': 'NX_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 211, 'prompt_tokens': 770, 'total_tokens': 981, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8d991e19-a7df-4f50-bf81-7c7d47d72922-0', tool_calls=[{'name': 'NX_QueryWrapper', 'args': {'query': 'Calculate the degree centrality for all games in the SteamGraph and return the 2nd and 4th most influential games based on their centrality scores.'}, 'id': 'call_XetPBbkgE9BGUNh3fAdi8i9D', 'type': 'tool_call'}], usage_metadata={'input_tokens': 770, 'output_tokens': 211, 'total_tokens': 981, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='null', name='NX_QueryWrapper', id='5d222471-7186-49c1-8bda-9b38acdf69cb', tool_call_id='call_XetPBbkgE9BGUNh3fAdi8i9D'),\n",
      "                AIMessage(content=\"It seems there was an issue with retrieving the centrality data. Let's try a different approach to identify the 2nd and 4th most influential games using the available tools.\\n\\n### Step 1 (Alternative): Identify the 2nd and 4th Most Influential Games\\n\\nWe will use the AQL query to find the games with the highest number of users (degree centrality) and identify the 2nd and 4th most influential games.\", additional_kwargs={'tool_calls': [{'id': 'call_xtAgVg02FjdVLfe0leIMhIEF', 'function': {'arguments': '{\"query\":\"FOR game IN Games\\\\nLET userCount = LENGTH(\\\\n  FOR play IN plays\\\\n  FILTER play._to == game._id\\\\n  RETURN play\\\\n)\\\\nSORT userCount DESC\\\\nLIMIT 4\\\\nRETURN {game: game.GameName, userCount: userCount}\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 168, 'prompt_tokens': 992, 'total_tokens': 1160, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9af4a4e4-b87c-431e-87d3-b69446b1f374-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'FOR game IN Games\\nLET userCount = LENGTH(\\n  FOR play IN plays\\n  FILTER play._to == game._id\\n  RETURN play\\n)\\nSORT userCount DESC\\nLIMIT 4\\nRETURN {game: game.GameName, userCount: userCount}'}, 'id': 'call_xtAgVg02FjdVLfe0leIMhIEF', 'type': 'tool_call'}], usage_metadata={'input_tokens': 992, 'output_tokens': 168, 'total_tokens': 1160, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The query results indicate the four most popular games based on the number of users who have played them. The game \"Dota 2\" has the highest user count with 4,841 players. It is followed by \"Team Fortress 2\" with 2,323 players, \"Counter-Strike Global Offensive\" with 1,377 players, and \"Unturned\" with 1,069 players.', name='AQL_QueryWrapper', id='8f930fea-0c24-4866-ab8b-5803b0a8b997', tool_call_id='call_xtAgVg02FjdVLfe0leIMhIEF')],\n",
      "  'user_query': 'Find 2nd and 4th Most influential game in the graph and its '\n",
      "                'number of users who played both of them'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH plays, Games, Users\n",
      "\n",
      "LET teamFortress2Users = (\n",
      "  FOR play IN plays\n",
      "  FILTER play._to == 'Games/team_fortress_2'\n",
      "  RETURN play._from\n",
      ")\n",
      "\n",
      "LET unturnedUsers = (\n",
      "  FOR play IN plays\n",
      "  FILTER play._to == 'Games/unturned'\n",
      "  RETURN play._from\n",
      ")\n",
      "\n",
      "LET commonUsers = INTERSECTION(teamFortress2Users, unturnedUsers)\n",
      "\n",
      "RETURN LENGTH(commonUsers)\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[0]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "print AQL tool result\n",
      "{'query': \"LET teamFortress2Users = (\\n  FOR play IN plays\\n  FILTER play._to == 'Games/team_fortress_2'\\n  RETURN play._from\\n)\\n\\nLET unturnedUsers = (\\n  FOR play IN plays\\n  FILTER play._to == 'Games/unturned'\\n  RETURN play._from\\n)\\n\\nLET commonUsers = INTERSECTION(teamFortress2Users, unturnedUsers)\\n\\nRETURN LENGTH(commonUsers)\", 'result': 'Summary:\\n\\nThere are no users who have played both \"Team Fortress 2\" and \"Unturned\" in the database.', 'aql_query': \"\\nWITH plays, Games, Users\\n\\nLET teamFortress2Users = (\\n  FOR play IN plays\\n  FILTER play._to == 'Games/team_fortress_2'\\n  RETURN play._from\\n)\\n\\nLET unturnedUsers = (\\n  FOR play IN plays\\n  FILTER play._to == 'Games/unturned'\\n  RETURN play._from\\n)\\n\\nLET commonUsers = INTERSECTION(teamFortress2Users, unturnedUsers)\\n\\nRETURN LENGTH(commonUsers)\\n\", 'aql_result': [0]}\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'data': [ { 'aql_query': '\\n'\n",
      "                           'WITH Games, plays\\n'\n",
      "                           'FOR game IN Games\\n'\n",
      "                           'LET userCount = LENGTH(\\n'\n",
      "                           '  FOR play IN plays\\n'\n",
      "                           '  FILTER play._to == game._id\\n'\n",
      "                           '  RETURN play\\n'\n",
      "                           ')\\n'\n",
      "                           'SORT userCount DESC\\n'\n",
      "                           'LIMIT 4\\n'\n",
      "                           'RETURN {game: game.GameName, userCount: '\n",
      "                           'userCount}\\n',\n",
      "              'aql_result': [ {'game': 'Dota 2', 'userCount': 4841},\n",
      "                              {'game': 'Team Fortress 2', 'userCount': 2323},\n",
      "                              { 'game': 'Counter-Strike Global Offensive',\n",
      "                                'userCount': 1377},\n",
      "                              {'game': 'Unturned', 'userCount': 1069}],\n",
      "              'query': 'FOR game IN Games\\n'\n",
      "                       'LET userCount = LENGTH(\\n'\n",
      "                       '  FOR play IN plays\\n'\n",
      "                       '  FILTER play._to == game._id\\n'\n",
      "                       '  RETURN play\\n'\n",
      "                       ')\\n'\n",
      "                       'SORT userCount DESC\\n'\n",
      "                       'LIMIT 4\\n'\n",
      "                       'RETURN {game: game.GameName, userCount: userCount}',\n",
      "              'result': 'The query results indicate the four most popular '\n",
      "                        'games based on the number of users who have played '\n",
      "                        'them. The game \"Dota 2\" has the highest user count '\n",
      "                        'with 4,841 players. It is followed by \"Team Fortress '\n",
      "                        '2\" with 2,323 players, \"Counter-Strike Global '\n",
      "                        'Offensive\" with 1,377 players, and \"Unturned\" with '\n",
      "                        '1,069 players.'},\n",
      "            { 'aql_query': '\\n'\n",
      "                           'WITH plays, Games, Users\\n'\n",
      "                           '\\n'\n",
      "                           'LET teamFortress2Users = (\\n'\n",
      "                           '  FOR play IN plays\\n'\n",
      "                           \"  FILTER play._to == 'Games/team_fortress_2'\\n\"\n",
      "                           '  RETURN play._from\\n'\n",
      "                           ')\\n'\n",
      "                           '\\n'\n",
      "                           'LET unturnedUsers = (\\n'\n",
      "                           '  FOR play IN plays\\n'\n",
      "                           \"  FILTER play._to == 'Games/unturned'\\n\"\n",
      "                           '  RETURN play._from\\n'\n",
      "                           ')\\n'\n",
      "                           '\\n'\n",
      "                           'LET commonUsers = INTERSECTION(teamFortress2Users, '\n",
      "                           'unturnedUsers)\\n'\n",
      "                           '\\n'\n",
      "                           'RETURN LENGTH(commonUsers)\\n',\n",
      "              'aql_result': [0],\n",
      "              'query': 'LET teamFortress2Users = (\\n'\n",
      "                       '  FOR play IN plays\\n'\n",
      "                       \"  FILTER play._to == 'Games/team_fortress_2'\\n\"\n",
      "                       '  RETURN play._from\\n'\n",
      "                       ')\\n'\n",
      "                       '\\n'\n",
      "                       'LET unturnedUsers = (\\n'\n",
      "                       '  FOR play IN plays\\n'\n",
      "                       \"  FILTER play._to == 'Games/unturned'\\n\"\n",
      "                       '  RETURN play._from\\n'\n",
      "                       ')\\n'\n",
      "                       '\\n'\n",
      "                       'LET commonUsers = INTERSECTION(teamFortress2Users, '\n",
      "                       'unturnedUsers)\\n'\n",
      "                       '\\n'\n",
      "                       'RETURN LENGTH(commonUsers)',\n",
      "              'result': 'Summary:\\n'\n",
      "                        '\\n'\n",
      "                        'There are no users who have played both \"Team '\n",
      "                        'Fortress 2\" and \"Unturned\" in the database.'}],\n",
      "  'messages': [ HumanMessage(content='Find 2nd and 4th Most influential game in the graph and its number of users who played both of them', additional_kwargs={}, response_metadata={}, id='800e2839-3631-462e-940b-74ec1e2c2b3c'),\n",
      "                AIMessage(content=\"To address the query, we need to follow these steps:\\n\\n1. **Identify the Most Influential Games**: Use centrality measures to determine the influence of games in the graph. We will use NetworkX to calculate the centrality of each game and identify the 2nd and 4th most influential games.\\n\\n2. **Find Users Who Played Both Games**: Once we have identified the 2nd and 4th most influential games, we will query the graph to find users who have played both of these games.\\n\\nLet's execute this plan step-by-step.\\n\\n### Step 1: Identify the 2nd and 4th Most Influential Games\\n\\nWe will use NetworkX to calculate the centrality of each game and determine the 2nd and 4th most influential games.\", additional_kwargs={'tool_calls': [{'id': 'call_XetPBbkgE9BGUNh3fAdi8i9D', 'function': {'arguments': '{\"query\":\"Calculate the degree centrality for all games in the SteamGraph and return the 2nd and 4th most influential games based on their centrality scores.\"}', 'name': 'NX_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 211, 'prompt_tokens': 770, 'total_tokens': 981, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8d991e19-a7df-4f50-bf81-7c7d47d72922-0', tool_calls=[{'name': 'NX_QueryWrapper', 'args': {'query': 'Calculate the degree centrality for all games in the SteamGraph and return the 2nd and 4th most influential games based on their centrality scores.'}, 'id': 'call_XetPBbkgE9BGUNh3fAdi8i9D', 'type': 'tool_call'}], usage_metadata={'input_tokens': 770, 'output_tokens': 211, 'total_tokens': 981, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='null', name='NX_QueryWrapper', id='5d222471-7186-49c1-8bda-9b38acdf69cb', tool_call_id='call_XetPBbkgE9BGUNh3fAdi8i9D'),\n",
      "                AIMessage(content=\"It seems there was an issue with retrieving the centrality data. Let's try a different approach to identify the 2nd and 4th most influential games using the available tools.\\n\\n### Step 1 (Alternative): Identify the 2nd and 4th Most Influential Games\\n\\nWe will use the AQL query to find the games with the highest number of users (degree centrality) and identify the 2nd and 4th most influential games.\", additional_kwargs={'tool_calls': [{'id': 'call_xtAgVg02FjdVLfe0leIMhIEF', 'function': {'arguments': '{\"query\":\"FOR game IN Games\\\\nLET userCount = LENGTH(\\\\n  FOR play IN plays\\\\n  FILTER play._to == game._id\\\\n  RETURN play\\\\n)\\\\nSORT userCount DESC\\\\nLIMIT 4\\\\nRETURN {game: game.GameName, userCount: userCount}\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 168, 'prompt_tokens': 992, 'total_tokens': 1160, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9af4a4e4-b87c-431e-87d3-b69446b1f374-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': 'FOR game IN Games\\nLET userCount = LENGTH(\\n  FOR play IN plays\\n  FILTER play._to == game._id\\n  RETURN play\\n)\\nSORT userCount DESC\\nLIMIT 4\\nRETURN {game: game.GameName, userCount: userCount}'}, 'id': 'call_xtAgVg02FjdVLfe0leIMhIEF', 'type': 'tool_call'}], usage_metadata={'input_tokens': 992, 'output_tokens': 168, 'total_tokens': 1160, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The query results indicate the four most popular games based on the number of users who have played them. The game \"Dota 2\" has the highest user count with 4,841 players. It is followed by \"Team Fortress 2\" with 2,323 players, \"Counter-Strike Global Offensive\" with 1,377 players, and \"Unturned\" with 1,069 players.', name='AQL_QueryWrapper', id='8f930fea-0c24-4866-ab8b-5803b0a8b997', tool_call_id='call_xtAgVg02FjdVLfe0leIMhIEF'),\n",
      "                AIMessage(content='The 2nd and 4th most influential games based on the number of users who have played them are:\\n\\n- 2nd Most Influential Game: **Team Fortress 2** with 2,323 players\\n- 4th Most Influential Game: **Unturned** with 1,069 players\\n\\n### Step 2: Find Users Who Played Both Games\\n\\nNow, we need to find the number of users who have played both \"Team Fortress 2\" and \"Unturned\". Let\\'s execute this query.', additional_kwargs={'tool_calls': [{'id': 'call_5TmAeQV9lkmLDacUW9DzUDC7', 'function': {'arguments': '{\"query\":\"LET teamFortress2Users = (\\\\n  FOR play IN plays\\\\n  FILTER play._to == \\'Games/team_fortress_2\\'\\\\n  RETURN play._from\\\\n)\\\\n\\\\nLET unturnedUsers = (\\\\n  FOR play IN plays\\\\n  FILTER play._to == \\'Games/unturned\\'\\\\n  RETURN play._from\\\\n)\\\\n\\\\nLET commonUsers = INTERSECTION(teamFortress2Users, unturnedUsers)\\\\n\\\\nRETURN LENGTH(commonUsers)\"}', 'name': 'AQL_QueryWrapper'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 222, 'prompt_tokens': 1254, 'total_tokens': 1476, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-147bec38-9a0f-4017-ae77-278991ad10c4-0', tool_calls=[{'name': 'AQL_QueryWrapper', 'args': {'query': \"LET teamFortress2Users = (\\n  FOR play IN plays\\n  FILTER play._to == 'Games/team_fortress_2'\\n  RETURN play._from\\n)\\n\\nLET unturnedUsers = (\\n  FOR play IN plays\\n  FILTER play._to == 'Games/unturned'\\n  RETURN play._from\\n)\\n\\nLET commonUsers = INTERSECTION(teamFortress2Users, unturnedUsers)\\n\\nRETURN LENGTH(commonUsers)\"}, 'id': 'call_5TmAeQV9lkmLDacUW9DzUDC7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1254, 'output_tokens': 222, 'total_tokens': 1476, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='Summary:\\n\\nThere are no users who have played both \"Team Fortress 2\" and \"Unturned\" in the database.', name='AQL_QueryWrapper', id='68147d80-85bb-45ff-aac6-8da8dd4b0bcb', tool_call_id='call_5TmAeQV9lkmLDacUW9DzUDC7')],\n",
      "  'user_query': 'Find 2nd and 4th Most influential game in the graph and its '\n",
      "                'number of users who played both of them'}\n",
      "Final Answer:\n",
      "Visulaization Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Visulaization Done'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query_graph(\"Find 2nd and 4th Most influential game in the graph and its number of users who played both of them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Agent State:\n",
      "{ 'messages': [ HumanMessage(content='Find the  top 10 users who played a lot  and which games they have played is common most by hours', additional_kwargs={}, response_metadata={}, id='f215f92d-4d51-4083-a4f8-0ea346a4fac7')],\n",
      "  'user_query': 'Find the  top 10 users who played a lot  and which games they '\n",
      "                'have played is common most by hours'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH Users, Games, plays\n",
      "FOR user IN Users\n",
      "    LET total_hours = SUM(\n",
      "        FOR play IN plays\n",
      "            FILTER play._from == user._id\n",
      "            RETURN play.weight\n",
      "    )\n",
      "    SORT total_hours DESC\n",
      "    LIMIT 10\n",
      "    RETURN { user_id: user._key, total_hours: total_hours }\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[{'user_id': '73017395', 'total_hours': 11754}, {'user_id': '10599862', 'total_hours': 11651.699999999999}, {'user_id': '100630947', 'total_hours': 10853.2}, {'user_id': '26762388', 'total_hours': 10470.100000000004}, {'user_id': '153382649', 'total_hours': 9640}, {'user_id': '43684632', 'total_hours': 9546.299999999988}, {'user_id': '48798067', 'total_hours': 9427.199999999997}, {'user_id': '52731290', 'total_hours': 9417.6}, {'user_id': '42935819', 'total_hours': 8172.9}, {'user_id': '14544587', 'total_hours': 8137.0999999999985}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'messages': [ HumanMessage(content='Find the  top 10 users who played a lot  and which games they have played is common most by hours', additional_kwargs={}, response_metadata={}, id='f215f92d-4d51-4083-a4f8-0ea346a4fac7'),\n",
      "                AIMessage(content=\"To address your query, I will follow these steps:\\n\\n1. **Identify the Top 10 Users by Playtime**: Use a query to find the top 10 users who have spent the most hours playing games.\\n2. **Determine Common Games Played**: For these top 10 users, identify which games are most commonly played by hours.\\n\\nLet's start with step 1. I will use the query processor to find the top 10 users by playtime.\", additional_kwargs={'tool_calls': [{'id': 'call_lv3ub4SVidhcGtCAiu8CLQpV', 'function': {'arguments': '{\"__arg1\":\"SELECT user_id, SUM(hours_played) as total_hours FROM user_game_data GROUP BY user_id ORDER BY total_hours DESC LIMIT 10\"}', 'name': 'query_processor'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 256, 'total_tokens': 396, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-371ed02c-8f63-44f9-aa6a-912ba7886cde-0', tool_calls=[{'name': 'query_processor', 'args': {'__arg1': 'SELECT user_id, SUM(hours_played) as total_hours FROM user_game_data GROUP BY user_id ORDER BY total_hours DESC LIMIT 10'}, 'id': 'call_lv3ub4SVidhcGtCAiu8CLQpV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 256, 'output_tokens': 140, 'total_tokens': 396, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content=\"The top 10 users with the highest total hours played on Steam are as follows:\\n\\n1. User with ID '73017395' has played for a total of 11,754 hours.\\n2. User with ID '10599862' has played for a total of 11,651.7 hours.\\n3. User with ID '100630947' has played for a total of 10,853.2 hours.\\n4. User with ID '26762388' has played for a total of 10,470.1 hours.\\n5. User with ID '153382649' has played for a total of 9,640 hours.\\n6. User with ID '43684632' has played for a total of 9,546.3 hours.\\n7. User with ID '48798067' has played for a total of 9,427.2 hours.\\n8. User with ID '52731290' has played for a total of 9,417.6 hours.\\n9. User with ID '42935819' has played for a total of 8,172.9 hours.\\n10. User with ID '14544587' has played for a total of 8,137.1 hours.\\n\\nThese users have the highest cumulative playtime across all games in the database.\", name='query_processor', id='22a044a6-13dc-43c5-bd80-c21813a53f86', tool_call_id='call_lv3ub4SVidhcGtCAiu8CLQpV')],\n",
      "  'user_query': 'Find the  top 10 users who played a lot  and which games they '\n",
      "                'have played is common most by hours'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH Users, Games, plays\n",
      "FOR user IN Users\n",
      "  FILTER user.steamid IN [73017395, 10599862, 100630947, 26762388, 153382649, 43684632, 48798067, 52731290, 42935819, 14544587]\n",
      "  FOR play IN plays\n",
      "    FILTER play._from == user._id\n",
      "    COLLECT game_id = play._to INTO grouped\n",
      "    LET total_hours = SUM(grouped[*].play.weight)\n",
      "    SORT total_hours DESC\n",
      "    RETURN { game_id, total_hours }\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[{'game_id': 'Games/11378_sid_meier_s_civilization_v', 'total_hours': 13197}, {'game_id': 'Games/11371_dota_2', 'total_hours': 10790.4}, {'game_id': 'Games/11359_team_fortress_2', 'total_hours': 9724.7}, {'game_id': 'Games/11389_counter_strike_global_offensive', 'total_hours': 5434.6}, {'game_id': 'Games/11624_mount_blade_warband', 'total_hours': 4962}, {'game_id': 'Games/13012_baldur_s_gate_ii_enhanced_edition', 'total_hours': 3970}, {'game_id': 'Games/12172_football_manager_2014', 'total_hours': 3382}, {'game_id': 'Games/12438_baldur_s_gate_enhanced_edition', 'total_hours': 2630}, {'game_id': 'Games/12146_football_manager_2015', 'total_hours': 2576}, {'game_id': 'Games/12145_football_manager_2012', 'total_hours': 2375}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Processing Agent State:\n",
      "{ 'messages': [ HumanMessage(content='Find the  top 10 users who played a lot  and which games they have played is common most by hours', additional_kwargs={}, response_metadata={}, id='f215f92d-4d51-4083-a4f8-0ea346a4fac7'),\n",
      "                AIMessage(content=\"To address your query, I will follow these steps:\\n\\n1. **Identify the Top 10 Users by Playtime**: Use a query to find the top 10 users who have spent the most hours playing games.\\n2. **Determine Common Games Played**: For these top 10 users, identify which games are most commonly played by hours.\\n\\nLet's start with step 1. I will use the query processor to find the top 10 users by playtime.\", additional_kwargs={'tool_calls': [{'id': 'call_lv3ub4SVidhcGtCAiu8CLQpV', 'function': {'arguments': '{\"__arg1\":\"SELECT user_id, SUM(hours_played) as total_hours FROM user_game_data GROUP BY user_id ORDER BY total_hours DESC LIMIT 10\"}', 'name': 'query_processor'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 256, 'total_tokens': 396, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-371ed02c-8f63-44f9-aa6a-912ba7886cde-0', tool_calls=[{'name': 'query_processor', 'args': {'__arg1': 'SELECT user_id, SUM(hours_played) as total_hours FROM user_game_data GROUP BY user_id ORDER BY total_hours DESC LIMIT 10'}, 'id': 'call_lv3ub4SVidhcGtCAiu8CLQpV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 256, 'output_tokens': 140, 'total_tokens': 396, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content=\"The top 10 users with the highest total hours played on Steam are as follows:\\n\\n1. User with ID '73017395' has played for a total of 11,754 hours.\\n2. User with ID '10599862' has played for a total of 11,651.7 hours.\\n3. User with ID '100630947' has played for a total of 10,853.2 hours.\\n4. User with ID '26762388' has played for a total of 10,470.1 hours.\\n5. User with ID '153382649' has played for a total of 9,640 hours.\\n6. User with ID '43684632' has played for a total of 9,546.3 hours.\\n7. User with ID '48798067' has played for a total of 9,427.2 hours.\\n8. User with ID '52731290' has played for a total of 9,417.6 hours.\\n9. User with ID '42935819' has played for a total of 8,172.9 hours.\\n10. User with ID '14544587' has played for a total of 8,137.1 hours.\\n\\nThese users have the highest cumulative playtime across all games in the database.\", name='query_processor', id='22a044a6-13dc-43c5-bd80-c21813a53f86', tool_call_id='call_lv3ub4SVidhcGtCAiu8CLQpV'),\n",
      "                AIMessage(content=\"We have identified the top 10 users with the highest total hours played. Now, let's proceed to step 2, where we will determine which games are most commonly played by these users based on hours. I will use the query processor to find the common games played by these top users.\", additional_kwargs={'tool_calls': [{'id': 'call_xHuq81UeIFLMSNcsktwybFB7', 'function': {'arguments': '{\"__arg1\":\"SELECT game_id, SUM(hours_played) as total_hours FROM user_game_data WHERE user_id IN (\\'73017395\\', \\'10599862\\', \\'100630947\\', \\'26762388\\', \\'153382649\\', \\'43684632\\', \\'48798067\\', \\'52731290\\', \\'42935819\\', \\'14544587\\') GROUP BY game_id ORDER BY total_hours DESC\"}', 'name': 'query_processor'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 155, 'prompt_tokens': 673, 'total_tokens': 828, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-70c3bd8e-d121-499f-9b43-3d412a1b6f41-0', tool_calls=[{'name': 'query_processor', 'args': {'__arg1': \"SELECT game_id, SUM(hours_played) as total_hours FROM user_game_data WHERE user_id IN ('73017395', '10599862', '100630947', '26762388', '153382649', '43684632', '48798067', '52731290', '42935819', '14544587') GROUP BY game_id ORDER BY total_hours DESC\"}, 'id': 'call_xHuq81UeIFLMSNcsktwybFB7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 673, 'output_tokens': 155, 'total_tokens': 828, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                ToolMessage(content='The query results show the total hours played for various games by a group of users with specific Steam IDs. The game with the highest total playtime is \"Sid Meier\\'s Civilization V\" with 13,197 hours. This is followed by \"Dota 2\" with 10,790.4 hours and \"Team Fortress 2\" with 9,724.7 hours. Other notable games include \"Counter-Strike: Global Offensive\" with 5,434.6 hours and \"Mount & Blade: Warband\" with 4,962 hours. The list continues with several other games, each with significant playtime, indicating the preferences and gaming habits of the users in question.', name='query_processor', id='33cd96db-331a-48e5-b1cf-12866dc9ea31', tool_call_id='call_xHuq81UeIFLMSNcsktwybFB7')],\n",
      "  'user_query': 'Find the  top 10 users who played a lot  and which games they '\n",
      "                'have played is common most by hours'}\n",
      "\n",
      "Debug - Final State:\n",
      "Number of messages: 6\n",
      "\n",
      "Message 1:\n",
      "Type: HumanMessage\n",
      "Content: Find the  top 10 users who played a lot  and which games they have played is common most by hours\n",
      "\n",
      "Message 2:\n",
      "Type: AIMessage\n",
      "Content: To address your query, I will follow these steps:\n",
      "\n",
      "1. **Identify the Top 10 Users by Playtime**: Use a query to find the top 10 users who have spent the most hours playing games.\n",
      "2. **Determine Common Games Played**: For these top 10 users, identify which games are most commonly played by hours.\n",
      "\n",
      "Let's start with step 1. I will use the query processor to find the top 10 users by playtime.\n",
      "Tool Calls:\n",
      "- Tool: query_processor\n",
      "  Arguments: {}\n",
      "\n",
      "Message 3:\n",
      "Type: ToolMessage\n",
      "Content: The top 10 users with the highest total hours played on Steam are as follows:\n",
      "\n",
      "1. User with ID '73017395' has played for a total of 11,754 hours.\n",
      "2. User with ID '10599862' has played for a total of 11,651.7 hours.\n",
      "3. User with ID '100630947' has played for a total of 10,853.2 hours.\n",
      "4. User with ID '26762388' has played for a total of 10,470.1 hours.\n",
      "5. User with ID '153382649' has played for a total of 9,640 hours.\n",
      "6. User with ID '43684632' has played for a total of 9,546.3 hours.\n",
      "7. User with ID '48798067' has played for a total of 9,427.2 hours.\n",
      "8. User with ID '52731290' has played for a total of 9,417.6 hours.\n",
      "9. User with ID '42935819' has played for a total of 8,172.9 hours.\n",
      "10. User with ID '14544587' has played for a total of 8,137.1 hours.\n",
      "\n",
      "These users have the highest cumulative playtime across all games in the database.\n",
      "\n",
      "Message 4:\n",
      "Type: AIMessage\n",
      "Content: We have identified the top 10 users with the highest total hours played. Now, let's proceed to step 2, where we will determine which games are most commonly played by these users based on hours. I will use the query processor to find the common games played by these top users.\n",
      "Tool Calls:\n",
      "- Tool: query_processor\n",
      "  Arguments: {}\n",
      "\n",
      "Message 5:\n",
      "Type: ToolMessage\n",
      "Content: The query results show the total hours played for various games by a group of users with specific Steam IDs. The game with the highest total playtime is \"Sid Meier's Civilization V\" with 13,197 hours. This is followed by \"Dota 2\" with 10,790.4 hours and \"Team Fortress 2\" with 9,724.7 hours. Other notable games include \"Counter-Strike: Global Offensive\" with 5,434.6 hours and \"Mount & Blade: Warband\" with 4,962 hours. The list continues with several other games, each with significant playtime, indicating the preferences and gaming habits of the users in question.\n",
      "\n",
      "Message 6:\n",
      "Type: AIMessage\n",
      "Content: Here are the top games most commonly played by the top 10 users based on total hours:\n",
      "\n",
      "1. **Sid Meier's Civilization V**: 13,197 hours\n",
      "2. **Dota 2**: 10,790.4 hours\n",
      "3. **Team Fortress 2**: 9,724.7 hours\n",
      "4. **Counter-Strike: Global Offensive**: 5,434.6 hours\n",
      "5. **Mount & Blade: Warband**: 4,962 hours\n",
      "\n",
      "These games are the most popular among the top 10 users with the highest playtime, indicating their gaming preferences.\n",
      "Final Answer:\n",
      "Here are the top games most commonly played by the top 10 users based on total hours:\n",
      "\n",
      "1. **Sid Meier's Civilization V**: 13,197 hours\n",
      "2. **Dota 2**: 10,790.4 hours\n",
      "3. **Team Fortress 2**: 9,724.7 hours\n",
      "4. **Counter-Strike: Global Offensive**: 5,434.6 hours\n",
      "5. **Mount & Blade: Warband**: 4,962 hours\n",
      "\n",
      "These games are the most popular among the top 10 users with the highest playtime, indicating their gaming preferences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here are the top games most commonly played by the top 10 users based on total hours:\\n\\n1. **Sid Meier's Civilization V**: 13,197 hours\\n2. **Dota 2**: 10,790.4 hours\\n3. **Team Fortress 2**: 9,724.7 hours\\n4. **Counter-Strike: Global Offensive**: 5,434.6 hours\\n5. **Mount & Blade: Warband**: 4,962 hours\\n\\nThese games are the most popular among the top 10 users with the highest playtime, indicating their gaming preferences.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query_graph(\"Find the  top 10 users who played a lot  and which games they have played is common most by hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Arrongo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
