{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:19:18 -0600] [INFO]: NetworkX-cuGraph is unavailable: No module named 'nx_cugraph'.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import nx_arangodb as nxadb\n",
    "\n",
    "from arango import ArangoClient\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import re\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.graphs import ArangoGraph\n",
    "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import gradio\n",
    "from graph_utils import create_d3_visualization\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access variables\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "arango_host = os.getenv('ARANGO_HOST')\n",
    "arango_user = os.getenv('ARANGO_USER')\n",
    "arango_password = os.getenv('ARANGO_PASSWORD')\n",
    "arango_db = os.getenv('ARANGO_DB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '195136', 'name': '_analyzers', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '195138', 'name': '_queues', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '195137', 'name': '_aqlfunctions', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '211044', 'name': 'Users', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '195139', 'name': '_jobs', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '211045', 'name': 'Games', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '195141', 'name': '_appbundles', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '195135', 'name': '_graphs', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '195140', 'name': '_apps', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '211046', 'name': 'plays', 'system': False, 'type': 'edge', 'status': 'loaded'}, {'id': '195142', 'name': '_frontend', 'system': True, 'type': 'document', 'status': 'loaded'}]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the client for ArangoDB.\n",
    "client = ArangoClient(hosts=arango_host)\n",
    "db = client.db(arango_db, username=arango_user, password=arango_password)\n",
    "print(db.collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:19:23 -0600] [INFO]: Graph 'SteamGraph' exists.\n",
      "[22:19:23 -0600] [INFO]: Default node type set to 'Games'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph named 'SteamGraph' with 14950 nodes and 70477 edges\n"
     ]
    }
   ],
   "source": [
    "\n",
    "G_adb = nxadb.Graph(name=\"SteamGraph\", db=db)\n",
    "\n",
    "print(G_adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_key': 'SteamGraph', '_id': '_graphs/SteamGraph', '_rev': '_jPbGLl2---', 'edgeDefinitions': [{'collection': 'plays', 'from': ['Users'], 'to': ['Games']}], 'orphanCollections': [], 'networkx': {'name': 'SteamGraph'}}\n"
     ]
    }
   ],
   "source": [
    "graph_def = db.collection(\"_graphs\").get(\"SteamGraph\")\n",
    "print(graph_def)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users/97622055 Users/97622055\n",
      "Users/180063157 Users/180063157\n",
      "Users/183421285 Users/183421285\n",
      "Games/11982_star_conflict Games/11982_star_conflict\n",
      "Users/273163848 Users/273163848\n",
      "Users/227863398 Users/227863398\n",
      "Users/214299751 Users/214299751\n",
      "Games/14353_rwby_grimm_eclipse Games/14353_rwby_grimm_eclipse\n",
      "Users/113835971 Users/113835971\n",
      "Users/72978546 Users/72978546\n"
     ]
    }
   ],
   "source": [
    "for node, data in list(G_adb.nodes(data=True))[:10]:\n",
    "    print(node, data.get(\"_id\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph named 'SteamGraph' with 14950 nodes and 70477 edges\n"
     ]
    }
   ],
   "source": [
    "print(G_adb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AQL Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections:\n",
      "_analyzers\n",
      "_queues\n",
      "_aqlfunctions\n",
      "Users\n",
      "_jobs\n",
      "Games\n",
      "_appbundles\n",
      "_graphs\n",
      "_apps\n",
      "plays\n",
      "_frontend\n",
      "\n",
      "Graph collections:\n",
      "[{'edge_collection': 'plays', 'from_vertex_collections': ['Users'], 'to_vertex_collections': ['Games']}]\n"
     ]
    }
   ],
   "source": [
    "# First, let's check what collections exist\n",
    "print(\"Available collections:\")\n",
    "for collection in db.collections():\n",
    "    print(collection['name'])\n",
    "\n",
    "# Get the graph to see its collections\n",
    "graph = db.graph('SteamGraph')\n",
    "print(\"\\nGraph collections:\")\n",
    "print(graph.edge_definitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Users Nodes:\n",
      "{'_key': '99157622', '_id': 'Users/99157622', '_rev': '_jPaYbqS--p', 'type': 'Users', 'steamid': 99157622}\n",
      "{'_key': '213256245', '_id': 'Users/213256245', '_rev': '_jPaYbwS--i', 'type': 'Users', 'steamid': 213256245}\n",
      "{'_key': '93644606', '_id': 'Users/93644606', '_rev': '_jPaYbiC--e', 'type': 'Users', 'steamid': 93644606}\n",
      "----------\n",
      "Sample Plays Edges:\n",
      "{'_key': '30281', '_id': 'plays/30281', '_from': 'Users/279171078', '_to': 'Games/11841_no_more_room_in_hell', '_rev': '_jPaYgv6--Q', 'weight': 0.7}\n",
      "{'_key': '48115', '_id': 'plays/48115', '_from': 'Users/129117376', '_to': 'Games/12144_besiege', '_rev': '_jPaYhna--h', 'weight': 2.1}\n",
      "{'_key': '24487', '_id': 'plays/24487', '_from': 'Users/104120883', '_to': 'Games/11985_firefall', '_rev': '_jPaYgee--Q', 'weight': 1.3}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Query 3 random nodes from the Users collection.\n",
    "# -----------------------------------------------------------\n",
    "result_cursor = G_adb.query(\"\"\"\n",
    "    FOR node IN Users\n",
    "        SORT RAND()\n",
    "        LIMIT 3\n",
    "        RETURN node\n",
    "\"\"\")\n",
    "print(\"Sample Users Nodes:\")\n",
    "for node in result_cursor:\n",
    "    print(node)\n",
    "print('-'*10)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Query 3 random edges from the plays edge collection.\n",
    "# -----------------------------------------------------------\n",
    "result_cursor = G_adb.query(\"\"\"\n",
    "    FOR edge IN plays\n",
    "        SORT RAND()\n",
    "        LIMIT 3\n",
    "        RETURN edge\n",
    "\"\"\")\n",
    "print(\"Sample Plays Edges:\")\n",
    "for edge in result_cursor:\n",
    "    print(edge)\n",
    "print('-'*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arango_graph = ArangoGraph(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 9, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'stop', 'logprobs': None}, id='run-f136012b-52dc-4130-8163-84af1f3a4957-0', usage_metadata={'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "llm.invoke(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @tool\n",
    "# def text_to_aql_to_text(query: str):\n",
    "#     \"\"\"This tool is available to invoke the\n",
    "#     ArangoGraphQAChain object, which enables you to\n",
    "#     translate a Natural Language Query into AQL, execute\n",
    "#     the query, and translate the result back into Natural Language.\n",
    "#     \"\"\"\n",
    "\n",
    "#     llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "#     chain = ArangoGraphQAChain.from_llm(\n",
    "#     \tllm=llm,\n",
    "#     \tgraph=arango_graph,\n",
    "#     \tverbose=True,\n",
    "#         allow_dangerous_requests=True\n",
    "#     )\n",
    "    \n",
    "#     result = chain.invoke(query)\n",
    "\n",
    "#     return str(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def text_to_aql_to_text(query: str):\n",
    "    \"\"\"This tool is available to invoke the\n",
    "    ArangoGraphQAChain object, which enables you to\n",
    "    translate a Natural Language Query into AQL, execute\n",
    "    the query, and translate the result back into Natural Language.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "    # Add system message to guide AQL generation\n",
    "    system_message = \"\"\"You are an expert in ArangoDB and AQL query generation.\n",
    "    When counting connections between heroes and comics:\n",
    "    1. Use OUTBOUND or INBOUND instead of ANY to ensure consistent direction\n",
    "    2. Use graph traversal (FOR v, e, p IN 1..1 OUTBOUND) instead of edge collection filtering\n",
    "    3. Always verify node types in the traversal\n",
    "    4. Use consistent naming conventions\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    chain = ArangoGraphQAChain.from_llm(\n",
    "        llm=llm,\n",
    "        graph=arango_graph,\n",
    "        verbose=True,\n",
    "        allow_dangerous_requests=True,\n",
    "        system_message=system_message\n",
    "    )\n",
    "    \n",
    "    result = chain.invoke(query)\n",
    "\n",
    "    return str(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Graph Schema ===\n",
      "{\n",
      "  \"Graph Schema\": [\n",
      "    {\n",
      "      \"graph_name\": \"SteamGraph\",\n",
      "      \"edge_definitions\": [\n",
      "        {\n",
      "          \"edge_collection\": \"plays\",\n",
      "          \"from_vertex_collections\": [\n",
      "            \"Users\"\n",
      "          ],\n",
      "          \"to_vertex_collections\": [\n",
      "            \"Games\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"Collection Schema\": [\n",
      "    {\n",
      "      \"collection_name\": \"Users\",\n",
      "      \"collection_type\": \"document\",\n",
      "      \"document_properties\": [\n",
      "        {\n",
      "          \"name\": \"_key\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"_id\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"_rev\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"type\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"steamid\",\n",
      "          \"type\": \"int\"\n",
      "        }\n",
      "      ],\n",
      "      \"example_document\": {\n",
      "        \"_key\": \"151603712\",\n",
      "        \"_id\": \"Users/151603712\",\n",
      "        \"_rev\": \"_jPaYbhm---\",\n",
      "        \"type\": \"Users\",\n",
      "        \"steamid\": 151603712\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"collection_name\": \"Games\",\n",
      "      \"collection_type\": \"document\",\n",
      "      \"document_properties\": [\n",
      "        {\n",
      "          \"name\": \"_key\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"_id\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"_rev\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"type\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"GameName\",\n",
      "          \"type\": \"str\"\n",
      "        }\n",
      "      ],\n",
      "      \"example_document\": {\n",
      "        \"_key\": \"11350_the_elder_scrolls_v_skyrim\",\n",
      "        \"_id\": \"Games/11350_the_elder_scrolls_v_skyrim\",\n",
      "        \"_rev\": \"_jPaYcPm---\",\n",
      "        \"type\": \"Games\",\n",
      "        \"GameName\": \"The Elder Scrolls V Skyrim\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"collection_name\": \"plays\",\n",
      "      \"collection_type\": \"edge\",\n",
      "      \"edge_properties\": [\n",
      "        {\n",
      "          \"name\": \"_key\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"_id\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"_from\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"_to\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"_rev\",\n",
      "          \"type\": \"str\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"weight\",\n",
      "          \"type\": \"int\"\n",
      "        }\n",
      "      ],\n",
      "      \"example_edge\": {\n",
      "        \"_key\": \"0\",\n",
      "        \"_id\": \"plays/0\",\n",
      "        \"_from\": \"Users/151603712\",\n",
      "        \"_to\": \"Games/11350_the_elder_scrolls_v_skyrim\",\n",
      "        \"_rev\": \"_jPaYfL2---\",\n",
      "        \"weight\": 273\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Print schema in a readable format\n",
    "print(\"\\n=== Graph Schema ===\")\n",
    "print(json.dumps(arango_graph.schema, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define the Text to NetworkX/cuGraph Tool\n",
    "# Note: It is encouraged to experiment and improve this section! This is just a placeholder:\n",
    "\n",
    "@tool\n",
    "def text_to_nx_algorithm_to_text(query):\n",
    "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
    "    the ArangoDB Graph. You are responsible for accepting the\n",
    "    Natural Language Query, establishing which algorithm needs to\n",
    "    be executed, executing the algorithm, and translating the results back\n",
    "    to Natural Language, with respect to the original query.\n",
    "\n",
    "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
    "    this tool.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "    ######################\n",
    "    print(\"1) Generating NetworkX code\")\n",
    "\n",
    "    text_to_nx = llm.invoke(f\"\"\"\n",
    "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
    "\n",
    "    I have the following graph analysis query: {query}.\n",
    "\n",
    "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
    "\n",
    "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
    "\n",
    "    Only assume that networkx is installed, and other base python dependencies.\n",
    "\n",
    "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
    "\n",
    "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
    "\n",
    "    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
    "\n",
    "    Your code:\n",
    "    \"\"\").content\n",
    "\n",
    "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
    "    \n",
    "    print('-'*10)\n",
    "    print(text_to_nx_cleaned)\n",
    "    print('-'*10)\n",
    "\n",
    "    ######################\n",
    "\n",
    "    print(\"\\n2) Executing NetworkX code\")\n",
    "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
    "    local_vars = {}\n",
    "\n",
    "    try:\n",
    "        exec(text_to_nx_cleaned, global_vars, local_vars)\n",
    "        text_to_nx_final = text_to_nx\n",
    "    except Exception as e:\n",
    "        print(f\"EXEC ERROR: {e}\")\n",
    "        return f\"EXEC ERROR: {e}\"\n",
    "\n",
    "        # TODO: Consider experimenting with a code corrector!\n",
    "        attempt = 1\n",
    "        MAX_ATTEMPTS = 3\n",
    "\n",
    "        # while attempt <= MAX_ATTEMPTS\n",
    "            # ...\n",
    "\n",
    "    print('-'*10)\n",
    "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
    "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
    "    print('-'*10)\n",
    "\n",
    "    ######################\n",
    "\n",
    "    print(\"3) Formulating final answer\")\n",
    "\n",
    "    nx_to_text = llm.invoke(f\"\"\"\n",
    "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
    "\n",
    "        I have the following graph analysis query: {query}.\n",
    "\n",
    "        I have executed the following python code to help me answer my query:\n",
    "\n",
    "        ---\n",
    "        {text_to_nx_final}\n",
    "        ---\n",
    "\n",
    "        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n",
    "\n",
    "        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n",
    "        answer my query.\n",
    "        \n",
    "        Your response:\n",
    "    \"\"\").content\n",
    "\n",
    "    return nx_to_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [text_to_aql_to_text,text_to_nx_algorithm_to_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_graph(query):\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "    app = create_react_agent(llm, tools)    \n",
    "    final_state = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "    return final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
      "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
      "WITH Games, plays\n",
      "FOR game IN Games\n",
      "    LET playCount = LENGTH(\n",
      "        FOR play IN plays\n",
      "            FILTER play._to == game._id\n",
      "            RETURN play\n",
      "    )\n",
      "    SORT playCount DESC\n",
      "    RETURN { GameName: game.GameName, PlayCount: playCount }\n",
      "\u001b[0m\n",
      "AQL Result:\n",
      "\u001b[32;1m\u001b[1;3m[{'GameName': 'Dota 2', 'PlayCount': 4841}, {'GameName': 'Team Fortress 2', 'PlayCount': 2323}, {'GameName': 'Counter-Strike Global Offensive', 'PlayCount': 1377}, {'GameName': 'Unturned', 'PlayCount': 1069}, {'GameName': 'Left 4 Dead 2', 'PlayCount': 801}, {'GameName': 'Counter-Strike Source', 'PlayCount': 715}, {'GameName': 'The Elder Scrolls V Skyrim', 'PlayCount': 677}, {'GameName': \"Garry's Mod\", 'PlayCount': 666}, {'GameName': 'Counter-Strike', 'PlayCount': 568}, {'GameName': \"Sid Meier's Civilization V\", 'PlayCount': 554}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The most popular games in the graph database, based on the number of times they have been played, are:\\n\\n1. **Dota 2** - 4,841 plays\\n2. **Team Fortress 2** - 2,323 plays\\n3. **Counter-Strike Global Offensive** - 1,377 plays\\n4. **Unturned** - 1,069 plays\\n5. **Left 4 Dead 2** - 801 plays\\n6. **Counter-Strike Source** - 715 plays\\n7. **The Elder Scrolls V Skyrim** - 677 plays\\n8. **Garry's Mod** - 666 plays\\n9. **Counter-Strike** - 568 plays\\n10. **Sid Meier's Civilization V** - 554 plays\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_graph(\"which fames ar ethe most popular? from the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://113e6f9ec11ad1ca8d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://113e6f9ec11ad1ca8d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dummy_query_graph(query):\n",
    "    # Simulate a query response\n",
    "    return \"Query processed successfully!\"\n",
    "\n",
    "def create_interface():\n",
    "    with gradio.Blocks(title=\"Marvel Heroes Graph Explorer\") as demo:\n",
    "        # Header\n",
    "        gradio.Markdown(\n",
    "            \"\"\"\n",
    "            # Marvel Heroes Graph Explorer\n",
    "            \n",
    "            This interface allows you to explore the Marvel Heroes and Comics graph database using natural language queries.\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        # Main interface\n",
    "        with gradio.Row():\n",
    "            with gradio.Column(scale=4):\n",
    "                query_input = gradio.Textbox(\n",
    "                    label=\"Enter your query\",\n",
    "                    placeholder=\"Example: Show me connections between heroes\",\n",
    "                    lines=3\n",
    "                )\n",
    "                with gradio.Row():\n",
    "                    submit_btn = gradio.Button(\"Submit\", variant=\"primary\")\n",
    "                    clear_btn = gradio.Button(\"Clear\")\n",
    "                \n",
    "            with gradio.Column(scale=6):\n",
    "                output = gradio.HTML(\n",
    "                    label=\"Result\"\n",
    "                )\n",
    "                \n",
    "        # Query history\n",
    "        with gradio.Accordion(\"Query History\", open=False):\n",
    "            history = gradio.HTML()\n",
    "        \n",
    "        def process_query(query, history_html):\n",
    "            # Get text result\n",
    "            result = dummy_query_graph(query)\n",
    "            \n",
    "            # Dummy data for visualization\n",
    "            sample_data = {\n",
    "                \"nodes\": [\n",
    "                    {\"id\": 1, \"name\": \"Spider-Man\"},\n",
    "                    {\"id\": 2, \"name\": \"Iron Man\"},\n",
    "                    {\"id\": 3, \"name\": \"Captain America\"},\n",
    "                    {\"id\": 4, \"name\": \"Thor\"},\n",
    "                    {\"id\": 5, \"name\": \"Black Widow\"}\n",
    "                ],\n",
    "                \"links\": [\n",
    "                    {\"source\": 1, \"target\": 2},\n",
    "                    {\"source\": 2, \"target\": 3},\n",
    "                    {\"source\": 1, \"target\": 3},\n",
    "                    {\"source\": 4, \"target\": 2},\n",
    "                    {\"source\": 3, \"target\": 4},\n",
    "                    {\"source\": 5, \"target\": 2},\n",
    "                    {\"source\": 5, \"target\": 3}\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            # Generate visualization HTML\n",
    "            viz_html = create_d3_visualization(sample_data[\"nodes\"], sample_data[\"links\"])\n",
    "            \n",
    "            # Combine text result with visualization\n",
    "            combined_result = f\"\"\"\n",
    "            <div class=\"result-container\">\n",
    "                <div style=\"margin-bottom: 20px; padding: 10px; background-color: #f5f5f5; border-radius: 5px;\">\n",
    "                    <p><strong>Query Result:</strong> {result}</p>\n",
    "                </div>\n",
    "                {viz_html}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            new_history = f\"<p><strong>Q:</strong> {query}<br><strong>A:</strong> {result}</p>\" + history_html\n",
    "            return combined_result, new_history \n",
    "        \n",
    "        def clear_inputs():\n",
    "            return \"\", \"\"\n",
    "        \n",
    "        submit_btn.click(\n",
    "            process_query,\n",
    "            inputs=[query_input, history],\n",
    "            outputs=[output, history]\n",
    "        )\n",
    "        \n",
    "        clear_btn.click(\n",
    "            clear_inputs,\n",
    "            inputs=[],\n",
    "            outputs=[query_input, output]\n",
    "        )\n",
    "        \n",
    "        query_input.submit(\n",
    "            process_query,\n",
    "            inputs=[query_input, history],\n",
    "            outputs=[output, history]\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch the interface\n",
    "create_interface().launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Arrongo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
